{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 학습 main 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. jpg to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "class_num = 5\n",
    "\n",
    "train_files = glob.glob(\"5_dataset/train/*/*.jpg\")\n",
    "val_files = glob.glob(\"5_dataset/val/*/*.jpg\")\n",
    "test_files = glob.glob(\"5_dataset/test/*/*.jpg\")\n",
    "\n",
    "y_temp_train = []\n",
    "y_temp_validation = []\n",
    "y_temp_test = []\n",
    "\n",
    "train_temp_files = []\n",
    "val_temp_files = []\n",
    "test_temp_files = []\n",
    "\n",
    "for _file in train_files:\n",
    "    train_temp_files.append(_file)\n",
    "    _label = _file.split(\"\\\\\")\n",
    "    y_temp_train.append(int(_label[1][4]))\n",
    "\n",
    "for _file in val_files:\n",
    "    val_temp_files.append(_file)\n",
    "    _label = _file.split(\"\\\\\")\n",
    "    y_temp_validation.append(int(_label[1][4]))    \n",
    "\n",
    "for _file in test_files:\n",
    "    test_temp_files.append(_file)\n",
    "    _label = _file.split(\"\\\\\")\n",
    "    y_temp_test.append(int(_label[1][4]))  \n",
    "    \n",
    "image_width = 331\n",
    "image_height = 221\n",
    "channels = 3\n",
    "\n",
    "x_train = np.ndarray(shape = (len(train_temp_files), image_width, image_height, channels), dtype = np.float32)\n",
    "y_train = np.ndarray(shape = (len(y_temp_train), class_num), dtype = np.float32)\n",
    "x_validation = np.ndarray(shape = (len(val_temp_files), image_width, image_height, channels), dtype = np.float32)\n",
    "y_validation = np.ndarray(shape = (len(y_temp_validation), class_num), dtype = np.float32)\n",
    "x_test = np.ndarray(shape = (len(test_temp_files), image_width, image_height, channels), dtype = np.float32)\n",
    "y_test = np.ndarray(shape = (len(y_temp_test), class_num), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(num):\n",
    "    arr = [0, 0, 0, 0, 0]\n",
    "    for i in range(class_num):\n",
    "        if (i==num):\n",
    "            arr[i] = 1\n",
    "        else:\n",
    "            arr[i] = 0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data converting complete\n",
      "validation data converting complete\n",
      "test data converting complete\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _file in train_files:\n",
    "    img = load_img(_file)\n",
    "    img.thumbnail((image_width, image_height))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((331, 221, 3))\n",
    "    x = (x-128.0)/128.0\n",
    "    x_train[i] = x\n",
    "    y_train[i] = one_hot_encoding(y_temp_train[i])\n",
    "    i += 1\n",
    "print(\"Train data converting complete\")\n",
    "\n",
    "i = 0\n",
    "for _file in val_files:\n",
    "    img = load_img(_file)\n",
    "    img.thumbnail((image_width, image_height))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((331, 221, 3))\n",
    "    x = (x-128.0)/128.0\n",
    "    x_validation[i] = x\n",
    "    y_validation[i] = one_hot_encoding(y_temp_validation[i])\n",
    "    i += 1\n",
    "print(\"validation data converting complete\")\n",
    "\n",
    "i = 0\n",
    "for _file in test_files:\n",
    "    img = load_img(_file)\n",
    "    img.thumbnail((image_width, image_height))\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((331, 221, 3))\n",
    "    x = (x-128.0)/128.0\n",
    "    x_test[i] = x\n",
    "    y_test[i] = one_hot_encoding(y_temp_test[i])\n",
    "    i += 1\n",
    "print(\"test data converting complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_train : \" + str(type(x_train)))\n",
    "print(\"y_train : \" + str(type(y_train)))\n",
    "print(\"x_validation : \" + str(type(x_validation)))\n",
    "print(\"y_validation : \" + str(type(y_validation)))\n",
    "print(\"x_test : \" + str(type(x_test)))\n",
    "print(\"y_test : \" + str(type(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. CNN with keras\n",
    "* ref url\n",
    "    * https://datascienceschool.net/view-notebook/51e147088d474fe1bf32e394394eaea7/\n",
    "    * http://pythonstudy.xyz/python/article/402-numpy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0\n",
    "    * https://snowdeer.github.io/machine-learning/2018/01/10/convolution-neural-network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <사용한 model 정보>\n",
    "* model1 : CRM CRM CRM CRM CRM FDD, epoch = 20, batch_size = 50\n",
    "* model2 : CRM CRM CRM CRM CRM FDD, epoch = 15, batch_size = 60\n",
    "* model3 : CRM CRM CRM CRM CRM FDD, epoch = 15, batch_size = 50 - good\n",
    "* model4 : CRM CRM CRM CRM CRM Drop(0.5) FDD, epoch = 15, batch_size = 50\n",
    "* model5 : CRM CRM Drop(0.25) CRM CRM CRM  FDD, epoch = 15, batch_size = 50\n",
    "* model6 : CRM CRM CRM CRM CRM Drop(0.25) FDD, epoch = 15, batch_size = 50\n",
    "---\n",
    "* 이 밑의 모델들은 비교적 후지다.  사용 안할 것\n",
    "    + model : CRM CRM + L2reg(0.001) CRM CRM CRM FDD, epoch = 15, batch_size = 50\n",
    "    + model : CRM CRM + L2reg(0.001) CRM CRM CRM Dropout(0.5) FDD, epoch = 15, batch_size = 50 \n",
    "    + model : CRM CRM CRM CRM CRM FDD, epoch = 15, batch_size = 40\n",
    "    + model : CRM CRM CRM Drop(0.25) CRM CRM CRM FDD, epoch = 15, batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(331, 221, 3))) # input size : 331, 221, 3\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "# model.add(layers.Conv2D(64, (3, 3), activity_regularizer = l2(0.001), activation='relu'))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(class_num, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = optimizers.RMSprop(lr = 1e-4),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15, batch_size=50, \n",
    "                    validation_data=(x_validation, y_validation),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('5classSoundModel'+str(model_num)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"5classSoundModelGraph\"+str(model_num)+\"-1.png\")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"5classSoundModelGraph\"+str(model_num)+\"-2.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 실제 test set에 대해 잘못된 판별 갯수 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "testList = glob.glob(\"5_dataset/test/*/*.jpg\")\n",
    "total = [0, 0, 0, 0, 0, 0]\n",
    "result = [0, 0, 0, 0, 0, 0]\n",
    "print(\"Length : \" + str(len(testList)))\n",
    "for i in tqdm_notebook(range(len(testList))):\n",
    "    predictNum = model.predict_classes(x_test[i:i+1, :], verbose = 0)\n",
    "    _ArrRealNum = testList[i].split(\"\\\\\")\n",
    "    realNum = int(_ArrRealNum[1].split(\"fold\")[-1])\n",
    "    total[realNum] = total[realNum] + 1\n",
    "    if(predictNum != realNum):\n",
    "        result[realNum] = result[realNum] + 1\n",
    "print(\"total : \" , end = \"\")\n",
    "print(total)\n",
    "print(\"result : \" , end = \"\")\n",
    "print(result)\n",
    "print(\"error% : \", end = \"\")\n",
    "for i in range(6):\n",
    "    temp = result[i] / total[i]\n",
    "    temp = temp * 100\n",
    "    print(round(temp, 3), end = \", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [0, 0, 0, 0, 0, 0]\n",
    "for i in y_test:\n",
    "    for j in range(6):\n",
    "        if(int(i[j]) == 1):\n",
    "            num[j] += 1\n",
    "for i in range(1, 6):\n",
    "    num[i] = num[i] + num[i-1]\n",
    "print(\"0 to \" + str(num[0]))\n",
    "print(str(num[0]+1) + \" to \" + str(num[1]))\n",
    "print(str(num[1]+1) + \" to \" + str(num[2]))\n",
    "print(str(num[2]+1) + \" to \" + str(num[3]))\n",
    "print(str(num[3]+1) + \" to \" + str(num[4]))\n",
    "print(str(num[4]+1) + \" to \" + str(num[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for i in range(len(testList)):\n",
    "    print(str(num), end = \" : \")\n",
    "    print(model.predict_classes(x_test[i:i+1, :], verbose = 0), end = \" , \")\n",
    "    if(i%10==0 and i != 0):\n",
    "        print(\"\\n\")\n",
    "    if(i==86 or i == 285 or i == 484 or i == 559 or i == 745):\n",
    "        print(\"\\n===========================================================================\")\n",
    "        print(\"\\n\")\n",
    "    num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
